#!/usr/bin/env python3
"""
Test de integraciÃ³n: scraping + normalizaciÃ³n
"""
from src.scraping import smart_scrape
from src.utils import filter_valid_links, clean_text, get_domain_name


def test_full_pipeline(url: str):
    print("\n" + "="*70)
    print(f"TEST INTEGRACIÃ“N: {url}")
    print("="*70)
    
    # 1. Scrapear
    print("\n1ï¸âƒ£ Scraping...")
    html, links, method = smart_scrape(url)
    
    if html is None:
        print("âŒ Error en scraping")
        return
    
    print(f"   âœ“ MÃ©todo: {method}")
    print(f"   âœ“ HTML: {len(html):,} chars")
    print(f"   âœ“ Enlaces crudos: {len(links)}")
    
    # 2. Normalizar y filtrar
    print("\n2ï¸âƒ£ Normalizando enlaces...")
    valid_links = filter_valid_links(links, url)
    print(f"   âœ“ Enlaces vÃ¡lidos: {len(valid_links)}")
    
    # 3. Limpiar texto
    print("\n3ï¸âƒ£ Limpiando texto...")
    clean = clean_text(html)
    print(f"   âœ“ Texto limpio: {len(clean):,} chars")
    
    # 4. Mostrar muestra
    print("\nğŸ“ Primeros 10 enlaces normalizados:")
    for i, link in enumerate(valid_links[:10], 1):
        print(f"   {i:2}. {link}")
    
    print("\nğŸ“„ Primeras 500 chars del texto limpio:")
    print(clean[:500])
    print("...")
    
    # 5. Nombre del dominio
    domain = get_domain_name(url)
    print(f"\nğŸ¢ Nombre del dominio: {domain}")
    
    return html, valid_links, clean


if __name__ == "__main__":
    # Test con HuggingFace
    test_full_pipeline("https://huggingface.co")
    
    print("\n" + "="*70)
    print("âœ… TEST DE INTEGRACIÃ“N COMPLETADO")
    print("="*70)